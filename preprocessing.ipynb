{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"v5ujpU\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v2.2.0/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"v5ujpU\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"v5ujpU\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages have been imported\n"
     ]
    }
   ],
   "source": [
    "# Import relevant libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import mne\n",
    "import mne_nirs\n",
    "\n",
    "from mne_nirs.experimental_design import make_first_level_design_matrix\n",
    "from mne_nirs.statistics import run_glm\n",
    "\n",
    "# %%\n",
    "# Import relevant libraries\n",
    "import os #computer stuff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #plots\n",
    "import pandas as pd #to work with datasets\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "import mne\n",
    "import mne_nirs\n",
    "\n",
    "# Import StatsModels\n",
    "import statsmodels.formula.api as smf\n",
    "import tqdm\n",
    "\n",
    "\n",
    "from mne_nirs.experimental_design import make_first_level_design_matrix #making design matrices\n",
    "from mne_nirs.statistics import run_glm #making ocntrasts\n",
    "from mne_nirs.statistics import statsmodels_to_results\n",
    "from mne_nirs.visualisation import plot_glm_group_topo\n",
    "from mne_nirs.visualisation import plot_glm_surface_projection\n",
    "from mne_nirs.channels import (get_long_channels, \n",
    "                               get_short_channels,\n",
    "                               picks_pair_to_idx) \n",
    "from mne.preprocessing.nirs import optical_density, beer_lambert_law\n",
    "\n",
    "from nilearn.plotting import plot_design_matrix #another project before mne nirs, they are using it for plotting design matrices\n",
    "\n",
    "from itertools import compress #for loops, iterations in general\n",
    "from icecream import ic #like \"print\"\n",
    "\n",
    "# Import MNE-BIDS processing\n",
    "from mne_bids import BIDSPath, read_raw_bids, get_entity_vals\n",
    "\n",
    "import matplotlib as mpl\n",
    "from lets_plot import *\n",
    "LetsPlot.setup_html()\n",
    "\n",
    "from plotnine import ggplot, aes, geom_line, geom_point, facet_grid, geom_hline\n",
    "\n",
    "print('packages have been imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was painful. Remember to check that you are installing the packages into the specific python environment (might have to use the terminal outside of VSC). Here, I use Python 3.9.7. \n",
    "Continuing to the preprocessing.\n",
    "\n",
    "First, we have some clever functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize(data, train_split):\n",
    "    \"\"\"\n",
    "    Normalize the data\n",
    "    \"\"\"\n",
    "    data_mean = data[:train_split].mean(axis=0)\n",
    "    data_std = data[:train_split].std(axis=0)\n",
    "    return (data - data_mean) / data_std\n",
    "\n",
    "\n",
    "def preprocess(raw_intensity, verbose=True):\n",
    "    \"\"\"\n",
    "    Loads the raw data from the path and procesess it\n",
    "    \"\"\"\n",
    "    #Â if verbose:\n",
    "    #     ic(\"Loading \", path)\n",
    "    # raw_intensity = mne.io.read_raw_snirf(raw_path, preload=True)\n",
    "    raw_od = mne.preprocessing.nirs.optical_density(raw_intensity)\n",
    "\n",
    "    # sci = mne.preprocessing.nirs.scalp_coupling_index(raw_od, l_freq=0.7, h_freq=1.5)\n",
    "    # raw_od.info['bads'] = list(compress(raw_od.ch_names, sci < 0.5))\n",
    "\n",
    "    # if verbose:\n",
    "    ic(\"Apply short channel regression.\")\n",
    "    od_corrected = mne_nirs.signal_enhancement.short_channel_regression(raw_od)\n",
    "\n",
    "    if verbose:\n",
    "        ic(\"Do temporal derivative distribution repair on:\", od_corrected)\n",
    "    tddr_od = mne.preprocessing.nirs.tddr(od_corrected)\n",
    "\n",
    "    if verbose:\n",
    "        ic(\"Convert to haemoglobin with the modified beer-lambert law.\")\n",
    "    raw_haemo = beer_lambert_law(tddr_od, ppf=0.1)\n",
    "\n",
    "    if verbose:\n",
    "        ic(\"Apply further data cleaning techniques and extract epochs.\")\n",
    "    raw_haemo = mne_nirs.signal_enhancement.enhance_negative_correlation(\n",
    "        raw_haemo)\n",
    "\n",
    "    # if verbose:\n",
    "    #     ic(\"Separate the long channels and short channels.\")\n",
    "    # sht_chans = get_short_channels(raw_haemo)\n",
    "    # raw_haemo = get_long_channels(raw_haemo)\n",
    "\n",
    "    # if verbose:\n",
    "    #     ic(\"Bandpass filter on:\", raw_haemo)\n",
    "    # filter_haemo = raw_haemo.filter(\n",
    "    #     0.01, 0.7, h_trans_bandwidth=0.3, l_trans_bandwidth=0.005)\n",
    "\n",
    "    # Create a design matrix\n",
    "    # design_matrix = make_first_level_design_matrix(raw_haemo)\n",
    "\n",
    "    # Append short channels mean to design matrix\n",
    "    # design_matrix[\"ShortHbO\"] = np.mean(\n",
    "    #     sht_chans.copy().pick(picks=\"hbo\").get_data(), axis=0)\n",
    "    # design_matrix[\"ShortHbR\"] = np.mean(\n",
    "    #     sht_chans.copy().pick(picks=\"hbr\").get_data(), axis=0)\n",
    "\n",
    "    return raw_haemo\n",
    "\n",
    "def individual_analysis(bids_path, ID, roi_1=[[4, 3], [1, 3], [3, 3], [1, 2], [2, 3], [1, 1]], roi_2=[[8, 7], [5, 7], [7, 7], [5, 6], [6, 7], [5, 5]], contrasts_1=['76','77'],contrasts_2=['78','79']):\n",
    "\n",
    "    # raw_intensity = read_raw_bids(bids_path=bids_path, verbose=False)\n",
    "    raw_intensity = mne.io.read_raw_snirf(bids_path)\n",
    "\n",
    "    raw_haemo = preprocess(raw_intensity)\n",
    "\n",
    "    # Cut out just the short channels for creating a GLM repressor\n",
    "    sht_chans = get_short_channels(raw_haemo)\n",
    "    raw_haemo = get_long_channels(raw_haemo)\n",
    "\n",
    "    # Create a design matrix\n",
    "    design_matrix = make_first_level_design_matrix(raw_haemo)\n",
    "\n",
    "    # Append short channels mean to design matrix\n",
    "    design_matrix[\"ShortHbO\"] = np.mean(sht_chans.copy().pick(picks=\"hbo\").get_data(), axis=0)\n",
    "    design_matrix[\"ShortHbR\"] = np.mean(sht_chans.copy().pick(picks=\"hbr\").get_data(), axis=0)\n",
    "\n",
    "    # Run GLM\n",
    "    glm_est = run_glm(raw_haemo, design_matrix)\n",
    "\n",
    "    # Define channels in each region of interest\n",
    "    # List the channel pairs manually\n",
    "    # Then generate the correct indices for each pair\n",
    "    groups = dict(\n",
    "        ROI_1=picks_pair_to_idx(raw_haemo, roi_1, on_missing='ignore'),\n",
    "        ROI_2=picks_pair_to_idx(raw_haemo, roi_2, on_missing='ignore'))\n",
    "\n",
    "    # Extract channel metrics\n",
    "    cha = glm_est.to_dataframe()\n",
    "\n",
    "    # Compute region of interest results from channel data\n",
    "    roi = glm_est.to_dataframe_region_of_interest(groups,\n",
    "                                                  design_matrix.columns,\n",
    "                                                  demographic_info=True)\n",
    "\n",
    "    # Define left vs right tapping contrast\n",
    "    contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "    basic_conts = dict([(column, contrast_matrix[i])\n",
    "                        for i, column in enumerate(design_matrix.columns)])\n",
    "\n",
    "    contrast_LvR = basic_conts[contrasts_1[0]]\n",
    "    for idx, con in enumerate(contrasts_1):\n",
    "        if idx != 0: contrast_LvR + basic_conts[con]\n",
    "    for con in contrasts_2:\n",
    "        contrast_LvR - basic_conts[con]\n",
    "    \n",
    "    # Compute defined contrast\n",
    "    contrast = glm_est.compute_contrast(contrast_LvR)\n",
    "    con = contrast.to_dataframe()\n",
    "\n",
    "    # Add the participant ID to the dataframes\n",
    "    roi[\"ID\"] = cha[\"ID\"] = con[\"ID\"] = ID\n",
    "\n",
    "    # Convert to uM for nicer plotting below.\n",
    "    cha[\"theta\"] = [t * 1.e6 for t in cha[\"theta\"]]\n",
    "    roi[\"theta\"] = [t * 1.e6 for t in roi[\"theta\"]]\n",
    "    con[\"effect\"] = [t * 1.e6 for t in con[\"effect\"]]\n",
    "\n",
    "    return raw_haemo, roi, cha, con\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we put in our information. That is, which files to preprocess, the regions of interest and contrasts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm on a roll\n"
     ]
    }
   ],
   "source": [
    "df_roi = pd.DataFrame()  # To store region of interest results\n",
    "df_cha = pd.DataFrame()  # To store channel level results\n",
    "df_con = pd.DataFrame()  # To store channel level contrast results\n",
    "\n",
    "subjects = [\n",
    "    \"/Users/al/Library/Mobile Documents/com~apple~CloudDocs/Cognitive Science ð§ /Bachelor's Thesis/Data/NCPE-2021-11-01/NP-Ph2-305-2021-11-01/2021-11-01_003.snirf\",\n",
    "    \"/Users/al/Library/Mobile Documents/com~apple~CloudDocs/Cognitive Science ð§ /Bachelor's Thesis/Data/NCPE-2021-11-04/NP-Ph2-306-2021-11-04/2021-11-04_001.snirf\"\n",
    "]\n",
    "\n",
    "for idx, sub in enumerate(subjects):\n",
    "    # Analyse data and return both ROI and channel results\n",
    "    raw_haemo, roi, channel, con = individual_analysis(sub, idx, roi_1=[[1,1], [1,2]], roi_2=[[4,4], [4,5]], contrasts_1=['76', '77'], contrasts_2=['78', '72'])\n",
    "\n",
    "    # Append individual results to all participants\n",
    "    df_roi = df_roi.append(roi)\n",
    "    df_cha = df_cha.append(channel)\n",
    "    df_con = df_con.append(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the good part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_results = df_roi.query(\"Condition in ['76', '77', '78']\")\n",
    "grp_results = grp_results.query(\"Chroma in ['hbo']\")\n",
    "\n",
    "grp_results.plot(x = \"Condition\", y = \"theta\")\n",
    "\n",
    "grp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_results = df_roi.query(\"Condition in ['76', '77', '78']\")\n",
    "\n",
    "roi_model = smf.mixedlm(\"theta ~ -1 + ROI:Condition:Chroma\",\n",
    "                        grp_results, groups=grp_results[\"ID\"]).fit(method='nm')\n",
    "roi_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "con_summary = df_con.query(\"Chroma in ['hbo']\")\n",
    "\n",
    "# Run group level model and convert to dataframe\n",
    "con_model = smf.mixedlm(\"effect ~ -1 + ch_name:Chroma\",\n",
    "                        con_summary, groups=con_summary[\"ID\"]).fit(method='nm')\n",
    "con_model_df = statsmodels_to_results(con_model,\n",
    "                                      order=raw_haemo.copy().pick(\n",
    "                                          picks=\"hbo\").ch_names)\n",
    "\n",
    "con_model_df['Coef.'] = -con_model_df['Coef.']\n",
    "\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbo\"),\n",
    "                    con_model_df, colorbar=True, axes=axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate brain figure from data\n",
    "clim = dict(kind='value', pos_lims=(0, 8, 11))\n",
    "brain = plot_glm_surface_projection(raw_haemo.copy().pick(\"hbo\"),\n",
    "                                    con_model_df, clim=clim, view='dorsal',\n",
    "                                    colorbar=True, size=(800, 700))\n",
    "brain.add_text(0.05, 0.95, \"Left-Right\", 'title', font_size=16, color='k')\n",
    "\n",
    "# Run model code as above\n",
    "clim = dict(kind='value', pos_lims=(0, 11.5, 17))\n",
    "for idx, cond in enumerate(['76', '78']):\n",
    "\n",
    "    # Run same model as explained in the sections above\n",
    "    ch_summary = df_cha.query(\"Condition in [@cond]\")\n",
    "    ch_summary = ch_summary.query(\"Chroma in ['hbo']\")\n",
    "    ch_model = smf.mixedlm(\"theta ~ -1 + ch_name\", ch_summary,\n",
    "                           groups=ch_summary[\"ID\"]).fit(method='nm')\n",
    "    model_df = statsmodels_to_results(ch_model, order=raw_haemo.copy().pick(\"hbo\").ch_names)\n",
    "\n",
    "    # Generate brain figure from data\n",
    "    brain = plot_glm_surface_projection(raw_haemo.copy().pick(\"hbo\"),\n",
    "                                        model_df, clim=clim, view='dorsal',\n",
    "                                        colorbar=True, size=(800, 700))\n",
    "    brain.add_text(0.05, 0.95, cond, 'title', font_size=16, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_haemo = preprocess(mne.io.read_raw_snirf(raw_path))\n",
    "events, event_dict = mne.events_from_annotations(raw_haemo, verbose=False)\n",
    "mne.viz.plot_events(events, event_id=event_dict, sfreq=raw_haemo.info['sfreq'])\n",
    "\n",
    "s = mne_nirs.experimental_design.create_boxcar(raw_haemo)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(15, 6))\n",
    "plt.plot(raw_haemo.times, s, axes=axes)\n",
    "plt.xlabel(\"Time (s)\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
